{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_samples > 0:\n",
    "    num_data = str(num_samples)\n",
    "else:\n",
    "    num_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the files\n",
    "X_train_raw = pd.read_csv(f'dataset/X_train{num_data}.tsv', sep='\\t')\n",
    "X_test_raw = pd.read_csv(f'dataset/X_test{num_data}.tsv', sep='\\t')\n",
    "y_train = pd.read_csv(f'dataset/y_train{num_data}.tsv', sep='\\t')\n",
    "y_test = pd.read_csv(f'dataset/y_test{num_data}.tsv', sep='\\t')\n",
    "\n",
    "# Save the current standard output\n",
    "original_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size\n",
    "input_size = X_train_raw.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "# Change the shape of the y_train to a 1d array\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 180)\n",
      "(1001, 180)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_raw\n",
    "X_test = X_test_raw\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF THE CELL\n"
     ]
    }
   ],
   "source": [
    "model_name = f'RF{num_data}'\n",
    "\n",
    "with open(f'reports/{model_name}.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        # Guarda el modelo\n",
    "        joblib.dump(model, f'models/{model_name}.pkl')\n",
    "\n",
    "        # Get the mean absolute error on the validation data\n",
    "        y_pred = model.predict(X_test)\n",
    "        MAE = metrics.mean_absolute_error(y_test , y_pred)\n",
    "        MSE = metrics.mean_squared_error(y_test , y_pred)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        # Print the metrics with 4 decimal digits\n",
    "        print('Model: ', model_name)\n",
    "        print(f'MAE = {MAE:.4f}')\n",
    "        print(f'MSE = {MSE:.4f}')\n",
    "        print(f'R2 = {r2:.4f}')\n",
    "\n",
    "# Restore the original standard output\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "print(\"END OF THE CELL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "160 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.06012373 -0.05935854\n",
      " -0.05899071 -0.05857456 -0.06678584 -0.06585225 -0.0656504  -0.06514856\n",
      "         nan         nan         nan         nan -0.04831637 -0.04687702\n",
      " -0.04739878 -0.04714133 -0.0525565  -0.05310331 -0.05290518 -0.05234076\n",
      "         nan         nan         nan         nan -0.04826537 -0.04746025\n",
      " -0.04715219 -0.04703491 -0.05312226 -0.05241599 -0.05161407 -0.05255003\n",
      "         nan         nan         nan         nan -0.04804758 -0.0472522\n",
      " -0.04806283 -0.04712673 -0.0523034  -0.05226949 -0.05219621 -0.05224682\n",
      "         nan         nan         nan         nan -0.06579044 -0.06599376\n",
      " -0.06543732 -0.0651098  -0.07069861 -0.07117787 -0.07161856 -0.07121099\n",
      "         nan         nan         nan         nan -0.05110926 -0.05012601\n",
      " -0.05065876 -0.05032775 -0.05596312 -0.05485421 -0.05454776 -0.05467053\n",
      "         nan         nan         nan         nan -0.05177147 -0.05046097\n",
      " -0.0493639  -0.04976899 -0.05461098 -0.05420534 -0.05420407 -0.05429349\n",
      "         nan         nan         nan         nan -0.05056582 -0.04949422\n",
      " -0.04960727 -0.04946477 -0.05605393 -0.05356451 -0.05329214 -0.05468492]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF THE CELL\n"
     ]
    }
   ],
   "source": [
    "model_name = f'RF{num_data}_GS'\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['squared_error', 'absolute_error']\n",
    "}\n",
    "\n",
    "with open(f'reports/{model_name}.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print('Model: ', model_name)\n",
    "        modelo_rf = RandomForestRegressor()\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=modelo_rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=7)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        print(f'Best parameters: {grid_search.best_params_}')\n",
    "        print(f'Best estimator: {grid_search.best_estimator_}')\n",
    "\n",
    "        # Save the model\n",
    "        joblib.dump(grid_search, f'models/{model_name}.pkl')\n",
    "\n",
    "        # Test the model\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "\n",
    "        print('================================================')\n",
    "        print('================================================')\n",
    "        MAE = metrics.mean_absolute_error(y_test , y_pred)\n",
    "        MSE = metrics.mean_squared_error(y_test , y_pred)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "        print(f'MAE = {MAE:.4f}')\n",
    "        print(f'MSE = {MSE:.4f}')\n",
    "        print(f'R2 = {r2:.4f}')\n",
    "        print('================================================')\n",
    "        print('================================================')\n",
    "\n",
    "# Restore the original standard output\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "print(\"END OF THE CELL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'NN{num_data}'\n",
    "\n",
    "with open(f'reports/{model_name}.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(128, input_dim=input_size, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(1, activation='linear'),\n",
    "        ])\n",
    "\n",
    "        # Compile the network :\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "        # Print the model summary\n",
    "        model.summary()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "        hist.tail()\n",
    "\n",
    "        # Save the model\n",
    "        model.save(f'models/{model_name}.h5')\n",
    "\n",
    "        # Test the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "        mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "        r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f'MSE: {mse}')\n",
    "        print(f'MAE: {mae}')\n",
    "        print(f'R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MAE]')\n",
    "  plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],  label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MAE^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values [MAE]')\n",
    "plt.ylabel('Predictions [MAE]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
