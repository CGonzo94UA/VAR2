{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the files\n",
    "X_train_raw = pd.read_csv('dataset/X_train.tsv', sep='\\t')\n",
    "X_test_raw = pd.read_csv('dataset/X_test.tsv', sep='\\t')\n",
    "y_train = pd.read_csv('dataset/y_train.tsv', sep='\\t')\n",
    "y_test = pd.read_csv('dataset/y_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train_raw.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_raw.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cgonz\\AppData\\Local\\Temp\\ipykernel_7196\\3776398501.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\cgonz\\AppData\\Local\\Temp\\ipykernel_7196\\3776398501.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "\n",
    "# Create a simple nn with 180 input values\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 18),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(18, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# training parameters\n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 50  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE: 0.596193253993988\n",
      "Epoch 1 MSE: 0.4895417094230652\n",
      "Epoch 2 MSE: 0.40776485204696655\n",
      "Epoch 3 MSE: 0.35822027921676636\n",
      "Epoch 4 MSE: 0.3244965374469757\n",
      "Epoch 5 MSE: 0.3036481440067291\n",
      "Epoch 6 MSE: 0.28943386673927307\n",
      "Epoch 7 MSE: 0.28007856011390686\n",
      "Epoch 8 MSE: 0.2729646861553192\n",
      "Epoch 9 MSE: 0.26640796661376953\n",
      "Epoch 10 MSE: 0.2602173686027527\n",
      "Epoch 11 MSE: 0.2557889223098755\n",
      "Epoch 12 MSE: 0.2521760165691376\n",
      "Epoch 13 MSE: 0.24819684028625488\n",
      "Epoch 14 MSE: 0.24579359591007233\n",
      "Epoch 15 MSE: 0.2430763840675354\n",
      "Epoch 16 MSE: 0.2429320216178894\n",
      "Epoch 17 MSE: 0.24066609144210815\n",
      "Epoch 18 MSE: 0.23943153023719788\n",
      "Epoch 19 MSE: 0.23889531195163727\n",
      "Epoch 20 MSE: 0.23620952665805817\n",
      "Epoch 21 MSE: 0.2366662621498108\n",
      "Epoch 22 MSE: 0.23553277552127838\n",
      "Epoch 23 MSE: 0.22904209792613983\n",
      "Epoch 24 MSE: 0.22842659056186676\n",
      "Epoch 25 MSE: 0.22478081285953522\n",
      "Epoch 26 MSE: 0.2241329401731491\n",
      "Epoch 27 MSE: 0.2241382598876953\n",
      "Epoch 28 MSE: 0.22628182172775269\n",
      "Epoch 29 MSE: 0.22138357162475586\n",
      "Epoch 30 MSE: 0.22025780379772186\n",
      "Epoch 31 MSE: 0.21627673506736755\n",
      "Epoch 32 MSE: 0.2125912755727768\n",
      "Epoch 33 MSE: 0.2103731632232666\n",
      "Epoch 34 MSE: 0.20977845788002014\n",
      "Epoch 35 MSE: 0.20787547528743744\n",
      "Epoch 36 MSE: 0.20639395713806152\n",
      "Epoch 37 MSE: 0.20696203410625458\n",
      "Epoch 38 MSE: 0.20570385456085205\n",
      "Epoch 39 MSE: 0.20498128235340118\n",
      "Epoch 40 MSE: 0.2041022628545761\n",
      "Epoch 41 MSE: 0.20327095687389374\n",
      "Epoch 42 MSE: 0.20559386909008026\n",
      "Epoch 43 MSE: 0.20196078717708588\n",
      "Epoch 44 MSE: 0.20135119557380676\n",
      "Epoch 45 MSE: 0.19991831481456757\n",
      "Epoch 46 MSE: 0.20152023434638977\n",
      "Epoch 47 MSE: 0.20218676328659058\n",
      "Epoch 48 MSE: 0.19827088713645935\n",
      "Epoch 49 MSE: 0.1972210556268692\n",
      "Epoch 50 MSE: 0.19422145187854767\n",
      "Epoch 51 MSE: 0.19322365522384644\n",
      "Epoch 52 MSE: 0.19270023703575134\n",
      "Epoch 53 MSE: 0.19138310849666595\n",
      "Epoch 54 MSE: 0.1895720362663269\n",
      "Epoch 55 MSE: 0.18767772614955902\n",
      "Epoch 56 MSE: 0.18918147683143616\n",
      "Epoch 57 MSE: 0.1887250691652298\n",
      "Epoch 58 MSE: 0.18548130989074707\n",
      "Epoch 59 MSE: 0.18488278985023499\n",
      "Epoch 60 MSE: 0.18682511150836945\n",
      "Epoch 61 MSE: 0.18562902510166168\n",
      "Epoch 62 MSE: 0.18478021025657654\n",
      "Epoch 63 MSE: 0.18302030861377716\n",
      "Epoch 64 MSE: 0.18348652124404907\n",
      "Epoch 65 MSE: 0.18276575207710266\n",
      "Epoch 66 MSE: 0.18264837563037872\n",
      "Epoch 67 MSE: 0.18292753398418427\n",
      "Epoch 68 MSE: 0.18238022923469543\n",
      "Epoch 69 MSE: 0.18152211606502533\n",
      "Epoch 70 MSE: 0.1809319257736206\n",
      "Epoch 71 MSE: 0.18053650856018066\n",
      "Epoch 72 MSE: 0.1819113790988922\n",
      "Epoch 73 MSE: 0.18134301900863647\n",
      "Epoch 74 MSE: 0.1827576458454132\n",
      "Epoch 75 MSE: 0.19030216336250305\n",
      "Epoch 76 MSE: 0.18319439888000488\n",
      "Epoch 77 MSE: 0.19505879282951355\n",
      "Epoch 78 MSE: 0.19472847878932953\n",
      "Epoch 79 MSE: 0.20109017193317413\n",
      "Epoch 80 MSE: 0.20455853641033173\n",
      "Epoch 81 MSE: 0.19877171516418457\n",
      "Epoch 82 MSE: 0.19741252064704895\n",
      "Epoch 83 MSE: 0.2028755247592926\n",
      "Epoch 84 MSE: 0.19180932641029358\n",
      "Epoch 85 MSE: 0.1957152634859085\n",
      "Epoch 86 MSE: 0.19166342914104462\n",
      "Epoch 87 MSE: 0.184855118393898\n",
      "Epoch 88 MSE: 0.19506360590457916\n",
      "Epoch 89 MSE: 0.1883440613746643\n",
      "Epoch 90 MSE: 0.1958777904510498\n",
      "Epoch 91 MSE: 0.18542852997779846\n",
      "Epoch 92 MSE: 0.1921396553516388\n",
      "Epoch 93 MSE: 0.18669170141220093\n",
      "Epoch 94 MSE: 0.18448111414909363\n",
      "Epoch 95 MSE: 0.18759413063526154\n",
      "Epoch 96 MSE: 0.18378609418869019\n",
      "Epoch 97 MSE: 0.17993299663066864\n",
      "Epoch 98 MSE: 0.1880091279745102\n",
      "Epoch 99 MSE: 0.18331323564052582\n",
      "Epoch 100 MSE: 0.18604795634746552\n",
      "Epoch 101 MSE: 0.18807674944400787\n",
      "Epoch 102 MSE: 0.1775646209716797\n",
      "Epoch 103 MSE: 0.18354947865009308\n",
      "Epoch 104 MSE: 0.17845268547534943\n",
      "Epoch 105 MSE: 0.17545562982559204\n",
      "Epoch 106 MSE: 0.17471954226493835\n",
      "Epoch 107 MSE: 0.17910544574260712\n",
      "Epoch 108 MSE: 0.17131246626377106\n",
      "Epoch 109 MSE: 0.16954781115055084\n",
      "Epoch 110 MSE: 0.16958262026309967\n",
      "Epoch 111 MSE: 0.16983070969581604\n",
      "Epoch 112 MSE: 0.17132586240768433\n",
      "Epoch 113 MSE: 0.1678488850593567\n",
      "Epoch 114 MSE: 0.16904059052467346\n",
      "Epoch 115 MSE: 0.16801407933235168\n",
      "Epoch 116 MSE: 0.1653602570295334\n",
      "Epoch 117 MSE: 0.1652606576681137\n",
      "Epoch 118 MSE: 0.16708119213581085\n",
      "Epoch 119 MSE: 0.16794820129871368\n",
      "Epoch 120 MSE: 0.1642741709947586\n",
      "Epoch 121 MSE: 0.16428746283054352\n",
      "Epoch 122 MSE: 0.1693461835384369\n",
      "Epoch 123 MSE: 0.16474780440330505\n",
      "Epoch 124 MSE: 0.1638755053281784\n",
      "Epoch 125 MSE: 0.16659463942050934\n",
      "Epoch 126 MSE: 0.16126976907253265\n",
      "Epoch 127 MSE: 0.1597738265991211\n",
      "Epoch 128 MSE: 0.1568601131439209\n",
      "Epoch 129 MSE: 0.1569894403219223\n",
      "Epoch 130 MSE: 0.15680727362632751\n",
      "Epoch 131 MSE: 0.15697510540485382\n",
      "Epoch 132 MSE: 0.15734806656837463\n",
      "Epoch 133 MSE: 0.15514980256557465\n",
      "Epoch 134 MSE: 0.1673165112733841\n",
      "Epoch 135 MSE: 0.15739360451698303\n",
      "Epoch 136 MSE: 0.15617528557777405\n",
      "Epoch 137 MSE: 0.15537138283252716\n",
      "Epoch 138 MSE: 0.15680056810379028\n",
      "Epoch 139 MSE: 0.1490117311477661\n",
      "Epoch 140 MSE: 0.15624229609966278\n",
      "Epoch 141 MSE: 0.16189230978488922\n",
      "Epoch 142 MSE: 0.15623921155929565\n",
      "Epoch 143 MSE: 0.15586470067501068\n",
      "Epoch 144 MSE: 0.15382413566112518\n",
      "Epoch 145 MSE: 0.160191148519516\n",
      "Epoch 146 MSE: 0.15086914598941803\n",
      "Epoch 147 MSE: 0.15548816323280334\n",
      "Epoch 148 MSE: 0.15091265738010406\n",
      "Epoch 149 MSE: 0.15150988101959229\n",
      "Epoch 150 MSE: 0.15062741935253143\n",
      "Epoch 151 MSE: 0.15041452646255493\n",
      "Epoch 152 MSE: 0.15155670046806335\n",
      "Epoch 153 MSE: 0.1558838039636612\n",
      "Epoch 154 MSE: 0.15575145184993744\n",
      "Epoch 155 MSE: 0.15188826620578766\n",
      "Epoch 156 MSE: 0.15141597390174866\n",
      "Epoch 157 MSE: 0.14880821108818054\n",
      "Epoch 158 MSE: 0.1558918058872223\n",
      "Epoch 159 MSE: 0.16095823049545288\n",
      "Epoch 160 MSE: 0.15253227949142456\n",
      "Epoch 161 MSE: 0.15236304700374603\n",
      "Epoch 162 MSE: 0.16494633257389069\n",
      "Epoch 163 MSE: 0.16357052326202393\n",
      "Epoch 164 MSE: 0.1591641902923584\n",
      "Epoch 165 MSE: 0.15298524498939514\n",
      "Epoch 166 MSE: 0.1531408131122589\n",
      "Epoch 167 MSE: 0.16672474145889282\n",
      "Epoch 168 MSE: 0.1634770631790161\n",
      "Epoch 169 MSE: 0.1515919417142868\n",
      "Epoch 170 MSE: 0.15121975541114807\n",
      "Epoch 171 MSE: 0.1518184095621109\n",
      "Epoch 172 MSE: 0.1569547802209854\n",
      "Epoch 173 MSE: 0.15546901524066925\n",
      "Epoch 174 MSE: 0.16218891739845276\n",
      "Epoch 175 MSE: 0.16220486164093018\n",
      "Epoch 176 MSE: 0.15398001670837402\n",
      "Epoch 177 MSE: 0.1603165566921234\n",
      "Epoch 178 MSE: 0.1608448624610901\n",
      "Epoch 179 MSE: 0.14936193823814392\n",
      "Epoch 180 MSE: 0.1542026251554489\n",
      "Epoch 181 MSE: 0.16410128772258759\n",
      "Epoch 182 MSE: 0.1538964807987213\n",
      "Epoch 183 MSE: 0.1924174576997757\n",
      "Epoch 184 MSE: 0.1549203246831894\n",
      "Epoch 185 MSE: 0.15574397146701813\n",
      "Epoch 186 MSE: 0.16598452627658844\n",
      "Epoch 187 MSE: 0.15949100255966187\n",
      "Epoch 188 MSE: 0.16083937883377075\n",
      "Epoch 189 MSE: 0.15559469163417816\n",
      "Epoch 190 MSE: 0.1575707495212555\n",
      "Epoch 191 MSE: 0.15893681347370148\n",
      "Epoch 192 MSE: 0.15622396767139435\n",
      "Epoch 193 MSE: 0.1857323944568634\n",
      "Epoch 194 MSE: 0.1594715416431427\n",
      "Epoch 195 MSE: 0.156509131193161\n",
      "Epoch 196 MSE: 0.18214207887649536\n",
      "Epoch 197 MSE: 0.1538356989622116\n",
      "Epoch 198 MSE: 0.15277524292469025\n",
      "Epoch 199 MSE: 0.15322791039943695\n",
      "Epoch 200 MSE: 0.14820346236228943\n",
      "Epoch 201 MSE: 0.15551485121250153\n",
      "Epoch 202 MSE: 0.1500023752450943\n",
      "Epoch 203 MSE: 0.1716133952140808\n",
      "Epoch 204 MSE: 0.15721450746059418\n",
      "Epoch 205 MSE: 0.15590724349021912\n",
      "Epoch 206 MSE: 0.16180379688739777\n",
      "Epoch 207 MSE: 0.1558295339345932\n",
      "Epoch 208 MSE: 0.15972191095352173\n",
      "Epoch 209 MSE: 0.1667601615190506\n",
      "Epoch 210 MSE: 0.156833678483963\n",
      "Epoch 211 MSE: 0.15981312096118927\n",
      "Epoch 212 MSE: 0.15066282451152802\n",
      "Epoch 213 MSE: 0.16405658423900604\n",
      "Epoch 214 MSE: 0.1580234318971634\n",
      "Epoch 215 MSE: 0.16829708218574524\n",
      "Epoch 216 MSE: 0.1548081636428833\n",
      "Epoch 217 MSE: 0.1599574238061905\n",
      "Epoch 218 MSE: 0.1523362696170807\n",
      "Epoch 219 MSE: 0.1541440188884735\n",
      "Epoch 220 MSE: 0.16393497586250305\n",
      "Epoch 221 MSE: 0.14883683621883392\n",
      "Epoch 222 MSE: 0.15450668334960938\n",
      "Epoch 223 MSE: 0.15303784608840942\n",
      "Epoch 224 MSE: 0.15135936439037323\n",
      "Epoch 225 MSE: 0.153681218624115\n",
      "Epoch 226 MSE: 0.16319593787193298\n",
      "Epoch 227 MSE: 0.1643742173910141\n",
      "Epoch 228 MSE: 0.15249520540237427\n",
      "Epoch 229 MSE: 0.16235925257205963\n",
      "Epoch 230 MSE: 0.17406171560287476\n",
      "Epoch 231 MSE: 0.1544708013534546\n",
      "Epoch 232 MSE: 0.1834840625524521\n",
      "Epoch 233 MSE: 0.15121519565582275\n",
      "Epoch 234 MSE: 0.1523205190896988\n",
      "Epoch 235 MSE: 0.15613411366939545\n",
      "Epoch 236 MSE: 0.17094749212265015\n",
      "Epoch 237 MSE: 0.1512793004512787\n",
      "Epoch 238 MSE: 0.1601768285036087\n",
      "Epoch 239 MSE: 0.16754676401615143\n",
      "Epoch 240 MSE: 0.15169622004032135\n",
      "Epoch 241 MSE: 0.15229180455207825\n",
      "Epoch 242 MSE: 0.1458543986082077\n",
      "Epoch 243 MSE: 0.1549665480852127\n",
      "Epoch 244 MSE: 0.15338537096977234\n",
      "Epoch 245 MSE: 0.16439032554626465\n",
      "Epoch 246 MSE: 0.15088467299938202\n",
      "Epoch 247 MSE: 0.15453699231147766\n",
      "Epoch 248 MSE: 0.14894065260887146\n",
      "Epoch 249 MSE: 0.16039232909679413\n",
      "Epoch 250 MSE: 0.15119442343711853\n",
      "Epoch 251 MSE: 0.156137615442276\n",
      "Epoch 252 MSE: 0.16808660328388214\n",
      "Epoch 253 MSE: 0.14822158217430115\n",
      "Epoch 254 MSE: 0.16750581562519073\n",
      "Epoch 255 MSE: 0.15292596817016602\n",
      "Epoch 256 MSE: 0.15862014889717102\n",
      "Epoch 257 MSE: 0.14863570034503937\n",
      "Epoch 258 MSE: 0.15727414190769196\n",
      "Epoch 259 MSE: 0.16489177942276\n",
      "Epoch 260 MSE: 0.14998513460159302\n",
      "Epoch 261 MSE: 0.16218645870685577\n",
      "Epoch 262 MSE: 0.173911452293396\n",
      "Epoch 263 MSE: 0.14718809723854065\n",
      "Epoch 264 MSE: 0.16465897858142853\n",
      "Epoch 265 MSE: 0.1503586322069168\n",
      "Epoch 266 MSE: 0.15743480622768402\n",
      "Epoch 267 MSE: 0.16389070451259613\n",
      "Epoch 268 MSE: 0.15883956849575043\n",
      "Epoch 269 MSE: 0.15965019166469574\n",
      "Epoch 270 MSE: 0.15764972567558289\n",
      "Epoch 271 MSE: 0.1600279062986374\n",
      "Epoch 272 MSE: 0.1540723592042923\n",
      "Epoch 273 MSE: 0.15597231686115265\n",
      "Epoch 274 MSE: 0.17629165947437286\n",
      "Epoch 275 MSE: 0.15834276378154755\n",
      "Epoch 276 MSE: 0.15174488723278046\n",
      "Epoch 277 MSE: 0.15889674425125122\n",
      "Epoch 278 MSE: 0.17338448762893677\n",
      "Epoch 279 MSE: 0.15154075622558594\n",
      "Epoch 280 MSE: 0.16543641686439514\n",
      "Epoch 281 MSE: 0.15371157228946686\n",
      "Epoch 282 MSE: 0.1547902673482895\n",
      "Epoch 283 MSE: 0.15861409902572632\n",
      "Epoch 284 MSE: 0.16627314686775208\n",
      "Epoch 285 MSE: 0.16845615208148956\n",
      "Epoch 286 MSE: 0.15713857114315033\n",
      "Epoch 287 MSE: 0.1585538536310196\n",
      "Epoch 288 MSE: 0.15985876321792603\n",
      "Epoch 289 MSE: 0.1593852937221527\n",
      "Epoch 290 MSE: 0.1614009141921997\n",
      "Epoch 291 MSE: 0.15613490343093872\n",
      "Epoch 292 MSE: 0.1567181497812271\n",
      "Epoch 293 MSE: 0.15939028561115265\n",
      "Epoch 294 MSE: 0.1611296683549881\n",
      "Epoch 295 MSE: 0.1634119302034378\n",
      "Epoch 296 MSE: 0.1585168093442917\n",
      "Epoch 297 MSE: 0.15766635537147522\n",
      "Epoch 298 MSE: 0.15993312001228333\n",
      "Epoch 299 MSE: 0.1686570942401886\n",
      "Epoch 300 MSE: 0.15003295242786407\n",
      "Epoch 301 MSE: 0.16295625269412994\n",
      "Epoch 302 MSE: 0.15821239352226257\n",
      "Epoch 303 MSE: 0.15842705965042114\n",
      "Epoch 304 MSE: 0.16084089875221252\n",
      "Epoch 305 MSE: 0.1560414582490921\n",
      "Epoch 306 MSE: 0.16161063313484192\n",
      "Epoch 307 MSE: 0.16594375669956207\n",
      "Epoch 308 MSE: 0.1551714688539505\n",
      "Epoch 309 MSE: 0.1653268039226532\n",
      "Epoch 310 MSE: 0.1581462025642395\n",
      "Epoch 311 MSE: 0.15965735912322998\n",
      "Epoch 312 MSE: 0.16385580599308014\n",
      "Epoch 313 MSE: 0.16322307288646698\n",
      "Epoch 314 MSE: 0.15335874259471893\n",
      "Epoch 315 MSE: 0.15827293694019318\n",
      "Epoch 316 MSE: 0.15974511206150055\n",
      "Epoch 317 MSE: 0.17560406029224396\n",
      "Epoch 318 MSE: 0.16591878235340118\n",
      "Epoch 319 MSE: 0.16919320821762085\n",
      "Epoch 320 MSE: 0.1598844975233078\n",
      "Epoch 321 MSE: 0.16114424169063568\n",
      "Epoch 322 MSE: 0.15328092873096466\n",
      "Epoch 323 MSE: 0.1600862443447113\n",
      "Epoch 324 MSE: 0.1539507508277893\n",
      "Epoch 325 MSE: 0.16349616646766663\n",
      "Epoch 326 MSE: 0.16099481284618378\n",
      "Epoch 327 MSE: 0.15685279667377472\n",
      "Epoch 328 MSE: 0.16108547151088715\n",
      "Epoch 329 MSE: 0.16050776839256287\n",
      "Epoch 330 MSE: 0.16098570823669434\n",
      "Epoch 331 MSE: 0.1603487879037857\n",
      "Epoch 332 MSE: 0.16812768578529358\n",
      "Epoch 333 MSE: 0.1680985540151596\n",
      "Epoch 334 MSE: 0.16495473682880402\n",
      "Epoch 335 MSE: 0.1635688990354538\n",
      "Epoch 336 MSE: 0.16201601922512054\n",
      "Epoch 337 MSE: 0.1563519537448883\n",
      "Epoch 338 MSE: 0.1687832474708557\n",
      "Epoch 339 MSE: 0.17152653634548187\n",
      "Epoch 340 MSE: 0.1620304435491562\n",
      "Epoch 341 MSE: 0.1625424474477768\n",
      "Epoch 342 MSE: 0.1690167635679245\n",
      "Epoch 343 MSE: 0.16697381436824799\n",
      "Epoch 344 MSE: 0.15660400688648224\n",
      "Epoch 345 MSE: 0.15389515459537506\n",
      "Epoch 346 MSE: 0.153477743268013\n",
      "Epoch 347 MSE: 0.15748466551303864\n",
      "Epoch 348 MSE: 0.15215851366519928\n",
      "Epoch 349 MSE: 0.15860596299171448\n",
      "Epoch 350 MSE: 0.1664874106645584\n",
      "Epoch 351 MSE: 0.15677808225154877\n",
      "Epoch 352 MSE: 0.17950086295604706\n",
      "Epoch 353 MSE: 0.14981460571289062\n",
      "Epoch 354 MSE: 0.14898419380187988\n",
      "Epoch 355 MSE: 0.14902356266975403\n",
      "Epoch 356 MSE: 0.14977622032165527\n",
      "Epoch 357 MSE: 0.14756019413471222\n",
      "Epoch 358 MSE: 0.1564323455095291\n",
      "Epoch 359 MSE: 0.16248959302902222\n",
      "Epoch 360 MSE: 0.15579457581043243\n",
      "Epoch 361 MSE: 0.1594848930835724\n",
      "Epoch 362 MSE: 0.14975076913833618\n",
      "Epoch 363 MSE: 0.14737457036972046\n",
      "Epoch 364 MSE: 0.15072688460350037\n",
      "Epoch 365 MSE: 0.1557459682226181\n",
      "Epoch 366 MSE: 0.1479203701019287\n",
      "Epoch 367 MSE: 0.15301845967769623\n",
      "Epoch 368 MSE: 0.15398024022579193\n",
      "Epoch 369 MSE: 0.1689726859331131\n",
      "Epoch 370 MSE: 0.16573020815849304\n",
      "Epoch 371 MSE: 0.16317951679229736\n",
      "Epoch 372 MSE: 0.1466091275215149\n",
      "Epoch 373 MSE: 0.1564476191997528\n",
      "Epoch 374 MSE: 0.1559697687625885\n",
      "Epoch 375 MSE: 0.15185964107513428\n",
      "Epoch 376 MSE: 0.143393874168396\n",
      "Epoch 377 MSE: 0.1546332985162735\n",
      "Epoch 378 MSE: 0.15189193189144135\n",
      "Epoch 379 MSE: 0.15331359207630157\n",
      "Epoch 380 MSE: 0.14426550269126892\n",
      "Epoch 381 MSE: 0.1411440670490265\n",
      "Epoch 382 MSE: 0.1523732990026474\n",
      "Epoch 383 MSE: 0.14626666903495789\n",
      "Epoch 384 MSE: 0.1534091830253601\n",
      "Epoch 385 MSE: 0.1441631019115448\n",
      "Epoch 386 MSE: 0.1471104919910431\n",
      "Epoch 387 MSE: 0.1488511860370636\n",
      "Epoch 388 MSE: 0.15449641644954681\n",
      "Epoch 389 MSE: 0.1476445347070694\n",
      "Epoch 390 MSE: 0.14926649630069733\n",
      "Epoch 391 MSE: 0.15832503139972687\n",
      "Epoch 392 MSE: 0.14691436290740967\n",
      "Epoch 393 MSE: 0.1470726579427719\n",
      "Epoch 394 MSE: 0.14652901887893677\n",
      "Epoch 395 MSE: 0.1452326774597168\n",
      "Epoch 396 MSE: 0.1482301503419876\n",
      "Epoch 397 MSE: 0.1444629430770874\n",
      "Epoch 398 MSE: 0.14396986365318298\n",
      "Epoch 399 MSE: 0.14480090141296387\n",
      "Epoch 400 MSE: 0.15256638824939728\n",
      "Epoch 401 MSE: 0.14950889348983765\n",
      "Epoch 402 MSE: 0.16010421514511108\n",
      "Epoch 403 MSE: 0.14701175689697266\n",
      "Epoch 404 MSE: 0.14632917940616608\n",
      "Epoch 405 MSE: 0.14992743730545044\n",
      "Epoch 406 MSE: 0.15416227281093597\n",
      "Epoch 407 MSE: 0.14998877048492432\n",
      "Epoch 408 MSE: 0.15725556015968323\n",
      "Epoch 409 MSE: 0.14250710606575012\n",
      "Epoch 410 MSE: 0.14349845051765442\n",
      "Epoch 411 MSE: 0.15083524584770203\n",
      "Epoch 412 MSE: 0.15298263728618622\n",
      "Epoch 413 MSE: 0.15054062008857727\n",
      "Epoch 414 MSE: 0.19624923169612885\n",
      "Epoch 415 MSE: 0.1558702290058136\n",
      "Epoch 416 MSE: 0.14413608610630035\n",
      "Epoch 417 MSE: 0.1430535763502121\n",
      "Epoch 418 MSE: 0.15387095510959625\n",
      "Epoch 419 MSE: 0.14913217723369598\n",
      "Epoch 420 MSE: 0.1424398124217987\n",
      "Epoch 421 MSE: 0.14705027639865875\n",
      "Epoch 422 MSE: 0.14382341504096985\n",
      "Epoch 423 MSE: 0.15007898211479187\n",
      "Epoch 424 MSE: 0.15191930532455444\n",
      "Epoch 425 MSE: 0.14917674660682678\n",
      "Epoch 426 MSE: 0.14777934551239014\n",
      "Epoch 427 MSE: 0.14544668793678284\n",
      "Epoch 428 MSE: 0.15569204092025757\n",
      "Epoch 429 MSE: 0.15196000039577484\n",
      "Epoch 430 MSE: 0.15254612267017365\n",
      "Epoch 431 MSE: 0.15150666236877441\n",
      "Epoch 432 MSE: 0.14298798143863678\n",
      "Epoch 433 MSE: 0.1477111279964447\n",
      "Epoch 434 MSE: 0.14869488775730133\n",
      "Epoch 435 MSE: 0.16140972077846527\n",
      "Epoch 436 MSE: 0.1458890736103058\n",
      "Epoch 437 MSE: 0.14575326442718506\n",
      "Epoch 438 MSE: 0.1937437802553177\n",
      "Epoch 439 MSE: 0.15519674122333527\n",
      "Epoch 440 MSE: 0.1454220563173294\n",
      "Epoch 441 MSE: 0.13814647495746613\n",
      "Epoch 442 MSE: 0.14708301424980164\n",
      "Epoch 443 MSE: 0.14952607452869415\n",
      "Epoch 444 MSE: 0.15353964269161224\n",
      "Epoch 445 MSE: 0.14439375698566437\n",
      "Epoch 446 MSE: 0.14485660195350647\n",
      "Epoch 447 MSE: 0.14439798891544342\n",
      "Epoch 448 MSE: 0.1538068801164627\n",
      "Epoch 449 MSE: 0.14319083094596863\n",
      "Epoch 450 MSE: 0.15368984639644623\n",
      "Epoch 451 MSE: 0.1477278769016266\n",
      "Epoch 452 MSE: 0.14283743500709534\n",
      "Epoch 453 MSE: 0.13771729171276093\n",
      "Epoch 454 MSE: 0.13896946609020233\n",
      "Epoch 455 MSE: 0.13482226431369781\n",
      "Epoch 456 MSE: 0.1389314979314804\n",
      "Epoch 457 MSE: 0.1467786282300949\n",
      "Epoch 458 MSE: 0.13659082353115082\n",
      "Epoch 459 MSE: 0.1432037055492401\n",
      "Epoch 460 MSE: 0.15214242041110992\n",
      "Epoch 461 MSE: 0.1386556327342987\n",
      "Epoch 462 MSE: 0.15544743835926056\n",
      "Epoch 463 MSE: 0.1542782038450241\n",
      "Epoch 464 MSE: 0.14565594494342804\n",
      "Epoch 465 MSE: 0.15256263315677643\n",
      "Epoch 466 MSE: 0.14533253014087677\n",
      "Epoch 467 MSE: 0.15274973213672638\n",
      "Epoch 468 MSE: 0.13802015781402588\n",
      "Epoch 469 MSE: 0.1411934345960617\n",
      "Epoch 470 MSE: 0.14020927250385284\n",
      "Epoch 471 MSE: 0.13458873331546783\n",
      "Epoch 472 MSE: 0.13881242275238037\n",
      "Epoch 473 MSE: 0.13700911402702332\n",
      "Epoch 474 MSE: 0.1402462273836136\n",
      "Epoch 475 MSE: 0.1414143294095993\n",
      "Epoch 476 MSE: 0.1400977373123169\n",
      "Epoch 477 MSE: 0.1677316278219223\n",
      "Epoch 478 MSE: 0.14384345710277557\n",
      "Epoch 479 MSE: 0.140844464302063\n",
      "Epoch 480 MSE: 0.14384663105010986\n",
      "Epoch 481 MSE: 0.14406752586364746\n",
      "Epoch 482 MSE: 0.14575664699077606\n",
      "Epoch 483 MSE: 0.13587221503257751\n",
      "Epoch 484 MSE: 0.13540703058242798\n",
      "Epoch 485 MSE: 0.14280995726585388\n",
      "Epoch 486 MSE: 0.144347682595253\n",
      "Epoch 487 MSE: 0.14300665259361267\n",
      "Epoch 488 MSE: 0.14579349756240845\n",
      "Epoch 489 MSE: 0.14347019791603088\n",
      "Epoch 490 MSE: 0.14242999255657196\n",
      "Epoch 491 MSE: 0.1402336210012436\n",
      "Epoch 492 MSE: 0.13966050744056702\n",
      "Epoch 493 MSE: 0.14014843106269836\n",
      "Epoch 494 MSE: 0.14336124062538147\n",
      "Epoch 495 MSE: 0.1511898636817932\n",
      "Epoch 496 MSE: 0.1404784768819809\n",
      "Epoch 497 MSE: 0.13915446400642395\n",
      "Epoch 498 MSE: 0.14969158172607422\n",
      "Epoch 499 MSE: 0.14378702640533447\n",
      "Epoch 500 MSE: 0.14174118638038635\n",
      "Epoch 501 MSE: 0.13759610056877136\n",
      "Epoch 502 MSE: 0.14096292853355408\n",
      "Epoch 503 MSE: 0.14725656807422638\n",
      "Epoch 504 MSE: 0.13539709150791168\n",
      "Epoch 505 MSE: 0.15165850520133972\n",
      "Epoch 506 MSE: 0.13966834545135498\n",
      "Epoch 507 MSE: 0.1407870054244995\n",
      "Epoch 508 MSE: 0.14208810031414032\n",
      "Epoch 509 MSE: 0.13691109418869019\n",
      "Epoch 510 MSE: 0.14756764471530914\n",
      "Epoch 511 MSE: 0.1563945710659027\n",
      "Epoch 512 MSE: 0.14581508934497833\n",
      "Epoch 513 MSE: 0.1392568200826645\n",
      "Epoch 514 MSE: 0.14347243309020996\n",
      "Epoch 515 MSE: 0.13600459694862366\n",
      "Epoch 516 MSE: 0.14015212655067444\n",
      "Epoch 517 MSE: 0.13384202122688293\n",
      "Epoch 518 MSE: 0.14608226716518402\n",
      "Epoch 519 MSE: 0.14694252610206604\n",
      "Epoch 520 MSE: 0.14689670503139496\n",
      "Epoch 521 MSE: 0.14847560226917267\n",
      "Epoch 522 MSE: 0.1416890025138855\n",
      "Epoch 523 MSE: 0.13997241854667664\n",
      "Epoch 524 MSE: 0.14110368490219116\n",
      "Epoch 525 MSE: 0.14122767746448517\n",
      "Epoch 526 MSE: 0.1488409787416458\n",
      "Epoch 527 MSE: 0.13939926028251648\n",
      "Epoch 528 MSE: 0.14132550358772278\n",
      "Epoch 529 MSE: 0.13678479194641113\n",
      "Epoch 530 MSE: 0.14295777678489685\n",
      "Epoch 531 MSE: 0.13795627653598785\n",
      "Epoch 532 MSE: 0.13626202940940857\n",
      "Epoch 533 MSE: 0.1437734216451645\n",
      "Epoch 534 MSE: 0.14226730167865753\n",
      "Epoch 535 MSE: 0.1388285607099533\n",
      "Epoch 536 MSE: 0.14237667620182037\n",
      "Epoch 537 MSE: 0.13756059110164642\n",
      "Epoch 538 MSE: 0.1447492092847824\n",
      "Epoch 539 MSE: 0.13680098950862885\n",
      "Epoch 540 MSE: 0.13625895977020264\n",
      "Epoch 541 MSE: 0.1556524932384491\n",
      "Epoch 542 MSE: 0.13872599601745605\n",
      "Epoch 543 MSE: 0.1307511180639267\n",
      "Epoch 544 MSE: 0.13779839873313904\n",
      "Epoch 545 MSE: 0.15776097774505615\n",
      "Epoch 546 MSE: 0.1435718834400177\n",
      "Epoch 547 MSE: 0.13540500402450562\n",
      "Epoch 548 MSE: 0.133748859167099\n",
      "Epoch 549 MSE: 0.18653932213783264\n",
      "Epoch 550 MSE: 0.13338851928710938\n",
      "Epoch 551 MSE: 0.1409716010093689\n",
      "Epoch 552 MSE: 0.13979721069335938\n",
      "Epoch 553 MSE: 0.1403687596321106\n",
      "Epoch 554 MSE: 0.13772234320640564\n",
      "Epoch 555 MSE: 0.1460481584072113\n",
      "Epoch 556 MSE: 0.14946213364601135\n",
      "Epoch 557 MSE: 0.16034042835235596\n",
      "Epoch 558 MSE: 0.1427588164806366\n",
      "Epoch 559 MSE: 0.14727666974067688\n",
      "Epoch 560 MSE: 0.15662813186645508\n",
      "Epoch 561 MSE: 0.13978315889835358\n",
      "Epoch 562 MSE: 0.14460857212543488\n",
      "Epoch 563 MSE: 0.15636982023715973\n",
      "Epoch 564 MSE: 0.14748317003250122\n",
      "Epoch 565 MSE: 0.142945796251297\n",
      "Epoch 566 MSE: 0.1394498199224472\n",
      "Epoch 567 MSE: 0.1522826850414276\n",
      "Epoch 568 MSE: 0.14707310497760773\n",
      "Epoch 569 MSE: 0.13658736646175385\n",
      "Epoch 570 MSE: 0.15108181536197662\n",
      "Epoch 571 MSE: 0.13729439675807953\n",
      "Epoch 572 MSE: 0.13419659435749054\n",
      "Epoch 573 MSE: 0.14097267389297485\n",
      "Epoch 574 MSE: 0.1430482566356659\n",
      "Epoch 575 MSE: 0.13841767609119415\n",
      "Epoch 576 MSE: 0.1435004621744156\n",
      "Epoch 577 MSE: 0.13845403492450714\n",
      "Epoch 578 MSE: 0.13952527940273285\n",
      "Epoch 579 MSE: 0.14322224259376526\n",
      "Epoch 580 MSE: 0.1536603718996048\n",
      "Epoch 581 MSE: 0.13813450932502747\n",
      "Epoch 582 MSE: 0.14168952405452728\n",
      "Epoch 583 MSE: 0.13982319831848145\n",
      "Epoch 584 MSE: 0.15127313137054443\n",
      "Epoch 585 MSE: 0.13277214765548706\n",
      "Epoch 586 MSE: 0.13721193373203278\n",
      "Epoch 587 MSE: 0.13653583824634552\n",
      "Epoch 588 MSE: 0.14036282896995544\n",
      "Epoch 589 MSE: 0.13938528299331665\n",
      "Epoch 590 MSE: 0.14678837358951569\n",
      "Epoch 591 MSE: 0.1480894535779953\n",
      "Epoch 592 MSE: 0.1427147388458252\n",
      "Epoch 593 MSE: 0.13514754176139832\n",
      "Epoch 594 MSE: 0.14779575169086456\n",
      "Epoch 595 MSE: 0.13611918687820435\n",
      "Epoch 596 MSE: 0.14196598529815674\n",
      "Epoch 597 MSE: 0.14178548753261566\n",
      "Epoch 598 MSE: 0.1507818102836609\n",
      "Epoch 599 MSE: 0.14769282937049866\n",
      "Epoch 600 MSE: 0.14750784635543823\n",
      "Epoch 601 MSE: 0.14312630891799927\n",
      "Epoch 602 MSE: 0.14844094216823578\n",
      "Epoch 603 MSE: 0.14548273384571075\n",
      "Epoch 604 MSE: 0.14205287396907806\n",
      "Epoch 605 MSE: 0.14888237416744232\n",
      "Epoch 606 MSE: 0.14004690945148468\n",
      "Epoch 607 MSE: 0.15999439358711243\n",
      "Epoch 608 MSE: 0.14340949058532715\n",
      "Epoch 609 MSE: 0.14079035818576813\n",
      "Epoch 610 MSE: 0.1394929736852646\n",
      "Epoch 611 MSE: 0.14210350811481476\n",
      "Epoch 612 MSE: 0.13499818742275238\n",
      "Epoch 613 MSE: 0.14141817390918732\n",
      "Epoch 614 MSE: 0.14401885867118835\n",
      "Epoch 615 MSE: 0.1361795961856842\n",
      "Epoch 616 MSE: 0.14446993172168732\n",
      "Epoch 617 MSE: 0.14501965045928955\n",
      "Epoch 618 MSE: 0.15167559683322906\n",
      "Epoch 619 MSE: 0.14080874621868134\n",
      "Epoch 620 MSE: 0.15388663113117218\n",
      "Epoch 621 MSE: 0.13437511026859283\n",
      "Epoch 622 MSE: 0.13673849403858185\n",
      "Epoch 623 MSE: 0.15744149684906006\n",
      "Epoch 624 MSE: 0.13334691524505615\n",
      "Epoch 625 MSE: 0.13532304763793945\n",
      "Epoch 626 MSE: 0.13850398361682892\n",
      "Epoch 627 MSE: 0.1341293305158615\n",
      "Epoch 628 MSE: 0.1379169523715973\n",
      "Epoch 629 MSE: 0.14008720219135284\n",
      "Epoch 630 MSE: 0.1376115381717682\n",
      "Epoch 631 MSE: 0.13794702291488647\n",
      "Epoch 632 MSE: 0.13507570326328278\n",
      "Epoch 633 MSE: 0.14041389524936676\n",
      "Epoch 634 MSE: 0.1435748189687729\n",
      "Epoch 635 MSE: 0.15048766136169434\n",
      "Epoch 636 MSE: 0.140097975730896\n",
      "Epoch 637 MSE: 0.16645200550556183\n",
      "Epoch 638 MSE: 0.152198925614357\n",
      "Epoch 639 MSE: 0.13762478530406952\n",
      "Epoch 640 MSE: 0.13991370797157288\n",
      "Epoch 641 MSE: 0.13642260432243347\n",
      "Epoch 642 MSE: 0.14067012071609497\n",
      "Epoch 643 MSE: 0.14956827461719513\n",
      "Epoch 644 MSE: 0.14417174458503723\n",
      "Epoch 645 MSE: 0.14819295704364777\n",
      "Epoch 646 MSE: 0.13743562996387482\n",
      "Epoch 647 MSE: 0.14512982964515686\n",
      "Epoch 648 MSE: 0.14410239458084106\n",
      "Epoch 649 MSE: 0.15605922043323517\n",
      "Epoch 650 MSE: 0.14551092684268951\n",
      "Epoch 651 MSE: 0.15487125515937805\n",
      "Epoch 652 MSE: 0.13689112663269043\n",
      "Epoch 653 MSE: 0.14994566142559052\n",
      "Epoch 654 MSE: 0.1403466761112213\n",
      "Epoch 655 MSE: 0.14238257706165314\n",
      "Epoch 656 MSE: 0.14330102503299713\n",
      "Epoch 657 MSE: 0.15082132816314697\n",
      "Epoch 658 MSE: 0.14173655211925507\n",
      "Epoch 659 MSE: 0.14371639490127563\n",
      "Epoch 660 MSE: 0.14314153790473938\n",
      "Epoch 661 MSE: 0.13728973269462585\n",
      "Epoch 662 MSE: 0.14222121238708496\n",
      "Epoch 663 MSE: 0.1471811830997467\n",
      "Epoch 664 MSE: 0.14196130633354187\n",
      "Epoch 665 MSE: 0.14394992589950562\n",
      "Epoch 666 MSE: 0.14570753276348114\n",
      "Epoch 667 MSE: 0.14063364267349243\n",
      "Epoch 668 MSE: 0.14795610308647156\n",
      "Epoch 669 MSE: 0.14858995378017426\n",
      "Epoch 670 MSE: 0.13561542332172394\n",
      "Epoch 671 MSE: 0.141829714179039\n",
      "Epoch 672 MSE: 0.13626010715961456\n",
      "Epoch 673 MSE: 0.14647705852985382\n",
      "Epoch 674 MSE: 0.1411784589290619\n",
      "Epoch 675 MSE: 0.14386890828609467\n",
      "Epoch 676 MSE: 0.14423330128192902\n",
      "Epoch 677 MSE: 0.14720477163791656\n",
      "Epoch 678 MSE: 0.14723335206508636\n",
      "Epoch 679 MSE: 0.14134395122528076\n",
      "Epoch 680 MSE: 0.1483704298734665\n",
      "Epoch 681 MSE: 0.1460186094045639\n",
      "Epoch 682 MSE: 0.14252065122127533\n",
      "Epoch 683 MSE: 0.1403689682483673\n",
      "Epoch 684 MSE: 0.14807714521884918\n",
      "Epoch 685 MSE: 0.16021956503391266\n",
      "Epoch 686 MSE: 0.14876346290111542\n",
      "Epoch 687 MSE: 0.13464365899562836\n",
      "Epoch 688 MSE: 0.13676998019218445\n",
      "Epoch 689 MSE: 0.13759782910346985\n",
      "Epoch 690 MSE: 0.14150890707969666\n",
      "Epoch 691 MSE: 0.1380719542503357\n",
      "Epoch 692 MSE: 0.1391265094280243\n",
      "Epoch 693 MSE: 0.13748019933700562\n",
      "Epoch 694 MSE: 0.144624724984169\n",
      "Epoch 695 MSE: 0.13494479656219482\n",
      "Epoch 696 MSE: 0.133353590965271\n",
      "Epoch 697 MSE: 0.12800930440425873\n",
      "Epoch 698 MSE: 0.13397003710269928\n",
      "Epoch 699 MSE: 0.13409243524074554\n",
      "Epoch 700 MSE: 0.14018544554710388\n",
      "Epoch 701 MSE: 0.13751791417598724\n",
      "Epoch 702 MSE: 0.1512480527162552\n",
      "Epoch 703 MSE: 0.14221256971359253\n",
      "Epoch 704 MSE: 0.14298556745052338\n",
      "Epoch 705 MSE: 0.13717709481716156\n",
      "Epoch 706 MSE: 0.14177706837654114\n",
      "Epoch 707 MSE: 0.13852497935295105\n",
      "Epoch 708 MSE: 0.1434524953365326\n",
      "Epoch 709 MSE: 0.1424078494310379\n",
      "Epoch 710 MSE: 0.14723700284957886\n",
      "Epoch 711 MSE: 0.14024795591831207\n",
      "Epoch 712 MSE: 0.13884250819683075\n",
      "Epoch 713 MSE: 0.134617879986763\n",
      "Epoch 714 MSE: 0.14566947519779205\n",
      "Epoch 715 MSE: 0.14173834025859833\n",
      "Epoch 716 MSE: 0.14429427683353424\n",
      "Epoch 717 MSE: 0.1477569341659546\n",
      "Epoch 718 MSE: 0.14795836806297302\n",
      "Epoch 719 MSE: 0.14601115882396698\n",
      "Epoch 720 MSE: 0.15143044292926788\n",
      "Epoch 721 MSE: 0.1482878029346466\n",
      "Epoch 722 MSE: 0.14614558219909668\n",
      "Epoch 723 MSE: 0.1532290130853653\n",
      "Epoch 724 MSE: 0.13607659935951233\n",
      "Epoch 725 MSE: 0.1471710056066513\n",
      "Epoch 726 MSE: 0.14949876070022583\n",
      "Epoch 727 MSE: 0.15245655179023743\n",
      "Epoch 728 MSE: 0.14480632543563843\n",
      "Epoch 729 MSE: 0.15418726205825806\n",
      "Epoch 730 MSE: 0.15388770401477814\n",
      "Epoch 731 MSE: 0.1385357677936554\n",
      "Epoch 732 MSE: 0.13673198223114014\n",
      "Epoch 733 MSE: 0.1415265053510666\n",
      "Epoch 734 MSE: 0.1513366997241974\n",
      "Epoch 735 MSE: 0.1482498049736023\n",
      "Epoch 736 MSE: 0.14106906950473785\n",
      "Epoch 737 MSE: 0.15095274150371552\n",
      "Epoch 738 MSE: 0.1538739800453186\n",
      "Epoch 739 MSE: 0.13416512310504913\n",
      "Epoch 740 MSE: 0.14446884393692017\n",
      "Epoch 741 MSE: 0.1377672255039215\n",
      "Epoch 742 MSE: 0.1369367092847824\n",
      "Epoch 743 MSE: 0.13822424411773682\n",
      "Epoch 744 MSE: 0.1453527808189392\n",
      "Epoch 745 MSE: 0.15510179102420807\n",
      "Epoch 746 MSE: 0.15207894146442413\n",
      "Epoch 747 MSE: 0.1572432816028595\n",
      "Epoch 748 MSE: 0.14116959273815155\n",
      "Epoch 749 MSE: 0.14747659862041473\n",
      "Epoch 750 MSE: 0.14563210308551788\n",
      "Epoch 751 MSE: 0.1419207900762558\n",
      "Epoch 752 MSE: 0.1472858041524887\n",
      "Epoch 753 MSE: 0.1444251835346222\n",
      "Epoch 754 MSE: 0.16257306933403015\n",
      "Epoch 755 MSE: 0.14234288036823273\n",
      "Epoch 756 MSE: 0.1445750594139099\n",
      "Epoch 757 MSE: 0.15170510113239288\n",
      "Epoch 758 MSE: 0.1418532133102417\n",
      "Epoch 759 MSE: 0.1404443085193634\n",
      "Epoch 760 MSE: 0.14381226897239685\n",
      "Epoch 761 MSE: 0.14621087908744812\n",
      "Epoch 762 MSE: 0.13811619579792023\n",
      "Epoch 763 MSE: 0.14058993756771088\n",
      "Epoch 764 MSE: 0.143480122089386\n",
      "Epoch 765 MSE: 0.1677180677652359\n",
      "Epoch 766 MSE: 0.1482175588607788\n",
      "Epoch 767 MSE: 0.14900222420692444\n",
      "Epoch 768 MSE: 0.14382614195346832\n",
      "Epoch 769 MSE: 0.14817015826702118\n",
      "Epoch 770 MSE: 0.134934201836586\n",
      "Epoch 771 MSE: 0.1477745920419693\n",
      "Epoch 772 MSE: 0.1436115801334381\n",
      "Epoch 773 MSE: 0.14322765171527863\n",
      "Epoch 774 MSE: 0.1412269026041031\n",
      "Epoch 775 MSE: 0.14254876971244812\n",
      "Epoch 776 MSE: 0.13906894624233246\n",
      "Epoch 777 MSE: 0.14098718762397766\n",
      "Epoch 778 MSE: 0.15692754089832306\n",
      "Epoch 779 MSE: 0.1591905802488327\n",
      "Epoch 780 MSE: 0.13871382176876068\n",
      "Epoch 781 MSE: 0.14400739967823029\n",
      "Epoch 782 MSE: 0.14228110015392303\n",
      "Epoch 783 MSE: 0.14308448135852814\n",
      "Epoch 784 MSE: 0.1425286829471588\n",
      "Epoch 785 MSE: 0.14277055859565735\n",
      "Epoch 786 MSE: 0.14423266053199768\n",
      "Epoch 787 MSE: 0.14958494901657104\n",
      "Epoch 788 MSE: 0.14201588928699493\n",
      "Epoch 789 MSE: 0.1450718492269516\n",
      "Epoch 790 MSE: 0.14241409301757812\n",
      "Epoch 791 MSE: 0.14873206615447998\n",
      "Epoch 792 MSE: 0.1469976305961609\n",
      "Epoch 793 MSE: 0.1518845409154892\n",
      "Epoch 794 MSE: 0.14774282276630402\n",
      "Epoch 795 MSE: 0.15436281263828278\n",
      "Epoch 796 MSE: 0.14361874759197235\n",
      "Epoch 797 MSE: 0.14367200434207916\n",
      "Epoch 798 MSE: 0.14908242225646973\n",
      "Epoch 799 MSE: 0.14708805084228516\n",
      "Epoch 800 MSE: 0.14609688520431519\n",
      "Epoch 801 MSE: 0.14533144235610962\n",
      "Epoch 802 MSE: 0.17052337527275085\n",
      "Epoch 803 MSE: 0.13912399113178253\n",
      "Epoch 804 MSE: 0.14062756299972534\n",
      "Epoch 805 MSE: 0.1370382159948349\n",
      "Epoch 806 MSE: 0.15049034357070923\n",
      "Epoch 807 MSE: 0.14692343771457672\n",
      "Epoch 808 MSE: 0.1508798748254776\n",
      "Epoch 809 MSE: 0.15031246840953827\n",
      "Epoch 810 MSE: 0.14271016418933868\n",
      "Epoch 811 MSE: 0.1510513722896576\n",
      "Epoch 812 MSE: 0.14686113595962524\n",
      "Epoch 813 MSE: 0.14130030572414398\n",
      "Epoch 814 MSE: 0.14256522059440613\n",
      "Epoch 815 MSE: 0.14914682507514954\n",
      "Epoch 816 MSE: 0.1643008291721344\n",
      "Epoch 817 MSE: 0.1468801200389862\n",
      "Epoch 818 MSE: 0.14396442472934723\n",
      "Epoch 819 MSE: 0.1532432734966278\n",
      "Epoch 820 MSE: 0.14826719462871552\n",
      "Epoch 821 MSE: 0.1487032175064087\n",
      "Epoch 822 MSE: 0.14518675208091736\n",
      "Epoch 823 MSE: 0.1496172547340393\n",
      "Epoch 824 MSE: 0.14785543084144592\n",
      "Epoch 825 MSE: 0.1549086570739746\n",
      "Epoch 826 MSE: 0.13796114921569824\n",
      "Epoch 827 MSE: 0.14766240119934082\n",
      "Epoch 828 MSE: 0.14599016308784485\n",
      "Epoch 829 MSE: 0.14876386523246765\n",
      "Epoch 830 MSE: 0.15220573544502258\n",
      "Epoch 831 MSE: 0.14925841987133026\n",
      "Epoch 832 MSE: 0.1500825583934784\n",
      "Epoch 833 MSE: 0.1488681584596634\n",
      "Epoch 834 MSE: 0.1457604169845581\n",
      "Epoch 835 MSE: 0.14777955412864685\n",
      "Epoch 836 MSE: 0.1488209068775177\n",
      "Epoch 837 MSE: 0.14828498661518097\n",
      "Epoch 838 MSE: 0.14578849077224731\n",
      "Epoch 839 MSE: 0.16532890498638153\n",
      "Epoch 840 MSE: 0.15346835553646088\n",
      "Epoch 841 MSE: 0.14585724472999573\n",
      "Epoch 842 MSE: 0.14838573336601257\n",
      "Epoch 843 MSE: 0.14721205830574036\n",
      "Epoch 844 MSE: 0.14851777255535126\n",
      "Epoch 845 MSE: 0.15164044499397278\n",
      "Epoch 846 MSE: 0.1484949141740799\n",
      "Epoch 847 MSE: 0.14342117309570312\n",
      "Epoch 848 MSE: 0.13790524005889893\n",
      "Epoch 849 MSE: 0.14358924329280853\n",
      "Epoch 850 MSE: 0.14284324645996094\n",
      "Epoch 851 MSE: 0.14057347178459167\n",
      "Epoch 852 MSE: 0.1421431303024292\n",
      "Epoch 853 MSE: 0.1465195268392563\n",
      "Epoch 854 MSE: 0.14386333525180817\n",
      "Epoch 855 MSE: 0.1612907499074936\n",
      "Epoch 856 MSE: 0.15033656358718872\n",
      "Epoch 857 MSE: 0.14965248107910156\n",
      "Epoch 858 MSE: 0.1419389396905899\n",
      "Epoch 859 MSE: 0.1439373642206192\n",
      "Epoch 860 MSE: 0.1470552682876587\n",
      "Epoch 861 MSE: 0.14401891827583313\n",
      "Epoch 862 MSE: 0.1645490676164627\n",
      "Epoch 863 MSE: 0.15714946389198303\n",
      "Epoch 864 MSE: 0.1416746824979782\n",
      "Epoch 865 MSE: 0.14567911624908447\n",
      "Epoch 866 MSE: 0.14554162323474884\n",
      "Epoch 867 MSE: 0.14349810779094696\n",
      "Epoch 868 MSE: 0.1449638158082962\n",
      "Epoch 869 MSE: 0.14339309930801392\n",
      "Epoch 870 MSE: 0.15369658172130585\n",
      "Epoch 871 MSE: 0.15184730291366577\n",
      "Epoch 872 MSE: 0.14298570156097412\n",
      "Epoch 873 MSE: 0.16732968389987946\n",
      "Epoch 874 MSE: 0.1496901512145996\n",
      "Epoch 875 MSE: 0.15047979354858398\n",
      "Epoch 876 MSE: 0.14190557599067688\n",
      "Epoch 877 MSE: 0.1373613327741623\n",
      "Epoch 878 MSE: 0.1349916011095047\n",
      "Epoch 879 MSE: 0.1352946013212204\n",
      "Epoch 880 MSE: 0.14471016824245453\n",
      "Epoch 881 MSE: 0.15185332298278809\n",
      "Epoch 882 MSE: 0.14225095510482788\n",
      "Epoch 883 MSE: 0.1468319296836853\n",
      "Epoch 884 MSE: 0.14776284992694855\n",
      "Epoch 885 MSE: 0.15807819366455078\n",
      "Epoch 886 MSE: 0.1507028490304947\n",
      "Epoch 887 MSE: 0.14843831956386566\n",
      "Epoch 888 MSE: 0.15054446458816528\n",
      "Epoch 889 MSE: 0.15424808859825134\n",
      "Epoch 890 MSE: 0.15135206282138824\n",
      "Epoch 891 MSE: 0.15158319473266602\n",
      "Epoch 892 MSE: 0.14801479876041412\n",
      "Epoch 893 MSE: 0.151399165391922\n",
      "Epoch 894 MSE: 0.14752300083637238\n",
      "Epoch 895 MSE: 0.14211124181747437\n",
      "Epoch 896 MSE: 0.149022176861763\n",
      "Epoch 897 MSE: 0.1471073478460312\n",
      "Epoch 898 MSE: 0.1458805501461029\n",
      "Epoch 899 MSE: 0.1447831094264984\n",
      "Epoch 900 MSE: 0.14629428088665009\n",
      "Epoch 901 MSE: 0.15001140534877777\n",
      "Epoch 902 MSE: 0.14471909403800964\n",
      "Epoch 903 MSE: 0.1451065093278885\n",
      "Epoch 904 MSE: 0.14228177070617676\n",
      "Epoch 905 MSE: 0.14709937572479248\n",
      "Epoch 906 MSE: 0.14147113263607025\n",
      "Epoch 907 MSE: 0.14804160594940186\n",
      "Epoch 908 MSE: 0.15502521395683289\n",
      "Epoch 909 MSE: 0.14832758903503418\n",
      "Epoch 910 MSE: 0.1591605544090271\n",
      "Epoch 911 MSE: 0.15308131277561188\n",
      "Epoch 912 MSE: 0.15448586642742157\n",
      "Epoch 913 MSE: 0.1498894840478897\n",
      "Epoch 914 MSE: 0.13698486983776093\n",
      "Epoch 915 MSE: 0.14893263578414917\n",
      "Epoch 916 MSE: 0.14277279376983643\n",
      "Epoch 917 MSE: 0.14950814843177795\n",
      "Epoch 918 MSE: 0.14977286756038666\n",
      "Epoch 919 MSE: 0.1499539017677307\n",
      "Epoch 920 MSE: 0.1506955623626709\n",
      "Epoch 921 MSE: 0.15085574984550476\n",
      "Epoch 922 MSE: 0.14226049184799194\n",
      "Epoch 923 MSE: 0.15348507463932037\n",
      "Epoch 924 MSE: 0.14350466430187225\n",
      "Epoch 925 MSE: 0.15374824404716492\n",
      "Epoch 926 MSE: 0.15046365559101105\n",
      "Epoch 927 MSE: 0.14859648048877716\n",
      "Epoch 928 MSE: 0.15045352280139923\n",
      "Epoch 929 MSE: 0.14677275717258453\n",
      "Epoch 930 MSE: 0.15268084406852722\n",
      "Epoch 931 MSE: 0.15420310199260712\n",
      "Epoch 932 MSE: 0.14632229506969452\n",
      "Epoch 933 MSE: 0.15873757004737854\n",
      "Epoch 934 MSE: 0.1549483835697174\n",
      "Epoch 935 MSE: 0.15064164996147156\n",
      "Epoch 936 MSE: 0.14736251533031464\n",
      "Epoch 937 MSE: 0.1488594114780426\n",
      "Epoch 938 MSE: 0.14529193937778473\n",
      "Epoch 939 MSE: 0.14575816690921783\n",
      "Epoch 940 MSE: 0.16359271109104156\n",
      "Epoch 941 MSE: 0.1519603133201599\n",
      "Epoch 942 MSE: 0.14354464411735535\n",
      "Epoch 943 MSE: 0.14241036772727966\n",
      "Epoch 944 MSE: 0.14142850041389465\n",
      "Epoch 945 MSE: 0.15000231564044952\n",
      "Epoch 946 MSE: 0.15730895102024078\n",
      "Epoch 947 MSE: 0.16296404600143433\n",
      "Epoch 948 MSE: 0.1547612100839615\n",
      "Epoch 949 MSE: 0.15149502456188202\n",
      "Epoch 950 MSE: 0.1510096937417984\n",
      "Epoch 951 MSE: 0.1520976573228836\n",
      "Epoch 952 MSE: 0.14339639246463776\n",
      "Epoch 953 MSE: 0.14829875528812408\n",
      "Epoch 954 MSE: 0.14926192164421082\n",
      "Epoch 955 MSE: 0.1639624387025833\n",
      "Epoch 956 MSE: 0.14739446341991425\n",
      "Epoch 957 MSE: 0.15243737399578094\n",
      "Epoch 958 MSE: 0.15455690026283264\n",
      "Epoch 959 MSE: 0.14856645464897156\n",
      "Epoch 960 MSE: 0.1745080202817917\n",
      "Epoch 961 MSE: 0.1484823077917099\n",
      "Epoch 962 MSE: 0.1631474494934082\n",
      "Epoch 963 MSE: 0.14980930089950562\n",
      "Epoch 964 MSE: 0.15103398263454437\n",
      "Epoch 965 MSE: 0.1563636213541031\n",
      "Epoch 966 MSE: 0.14603191614151\n",
      "Epoch 967 MSE: 0.14643380045890808\n",
      "Epoch 968 MSE: 0.15520860254764557\n",
      "Epoch 969 MSE: 0.15189465880393982\n",
      "Epoch 970 MSE: 0.14568357169628143\n",
      "Epoch 971 MSE: 0.15742045640945435\n",
      "Epoch 972 MSE: 0.1567450761795044\n",
      "Epoch 973 MSE: 0.15443027019500732\n",
      "Epoch 974 MSE: 0.14966464042663574\n",
      "Epoch 975 MSE: 0.14648914337158203\n",
      "Epoch 976 MSE: 0.14653682708740234\n",
      "Epoch 977 MSE: 0.15316812694072723\n",
      "Epoch 978 MSE: 0.1522606760263443\n",
      "Epoch 979 MSE: 0.15326903760433197\n",
      "Epoch 980 MSE: 0.14894726872444153\n",
      "Epoch 981 MSE: 0.15403294563293457\n",
      "Epoch 982 MSE: 0.14930787682533264\n",
      "Epoch 983 MSE: 0.14040693640708923\n",
      "Epoch 984 MSE: 0.14664888381958008\n",
      "Epoch 985 MSE: 0.1488351821899414\n",
      "Epoch 986 MSE: 0.1459628790616989\n",
      "Epoch 987 MSE: 0.1532321721315384\n",
      "Epoch 988 MSE: 0.15008920431137085\n",
      "Epoch 989 MSE: 0.15288236737251282\n",
      "Epoch 990 MSE: 0.1507250964641571\n",
      "Epoch 991 MSE: 0.15280427038669586\n",
      "Epoch 992 MSE: 0.1493953913450241\n",
      "Epoch 993 MSE: 0.1552882045507431\n",
      "Epoch 994 MSE: 0.15146797895431519\n",
      "Epoch 995 MSE: 0.14571622014045715\n",
      "Epoch 996 MSE: 0.15043988823890686\n",
      "Epoch 997 MSE: 0.1532329022884369\n",
      "Epoch 998 MSE: 0.1475663185119629\n",
      "Epoch 999 MSE: 0.15049345791339874\n",
      "MSE: 0.13\n",
      "RMSE: 0.36\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "            \n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    print(f\"Epoch {epoch} MSE: {mse}\")\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'prueba2'\n",
    "# Save the model\n",
    "torch.save(model, f'models/{model_name}.pt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=input_size),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "# Compile the network :\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=50, validation_data=(X_test, y_test))\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],  label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "# Change the shape of the y_train to a 1d array\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 180)\n",
      "(1001, 180)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_raw\n",
    "X_test = X_test_raw\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest validation MAE =  0.0824547981684442\n",
      "Random forest validation MSE =  0.04309882070461062\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "name = '3laps'\n",
    "\n",
    "# Guarda el modelo\n",
    "joblib.dump(model, f'models/RF_{name}.pkl')\n",
    "\n",
    "# Get the mean absolute error on the validation data\n",
    "y_pred = model.predict(X_test)\n",
    "MAE = metrics.mean_absolute_error(y_test , y_pred)\n",
    "MSE = metrics.mean_squared_error(y_test , y_pred)\n",
    "print('Random forest validation MAE = ', MAE)\n",
    "print('Random forest validation MSE = ', MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current standard output\n",
    "original_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m modelo_rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodelo_rf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest estimator: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cgonz\\tfgEnv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = '3lapsGridSearchCV'\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "with open(f'reports/{model_name}.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        modelo_rf = RandomForestRegressor()\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=modelo_rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        print(f'Best parameters: {grid_search.best_params_}')\n",
    "        print(f'Best estimator: {grid_search.best_estimator_}')\n",
    "\n",
    "        # Save the model\n",
    "        joblib.dump(grid_search, f'models/RF_{model_name}.pkl')\n",
    "\n",
    "        # Test the model\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "\n",
    "        print('================================================')\n",
    "        print('================================================')\n",
    "        MAE = metrics.mean_absolute_error(y_test , y_pred)\n",
    "        MSE = metrics.mean_squared_error(y_test , y_pred)\n",
    "        print('Random forest test MAE = ', MAE)\n",
    "        print('Random forest test MSE = ', MSE)\n",
    "        print('================================================')\n",
    "        print('================================================')\n",
    "\n",
    "# Restore the original standard output\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "print(\"END OF THE CELL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
